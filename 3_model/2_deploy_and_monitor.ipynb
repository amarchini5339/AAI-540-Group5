{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d18f6c",
   "metadata": {},
   "source": [
    "# Model Deployment & Monitoring\n",
    "\n",
    "**Goal:** Deploy the best XGBoost binary classifier from the hyperparameter tuning job\n",
    "to a persistent SageMaker real-time endpoint with **data capture**, create a\n",
    "**Model Monitor** baseline and hourly schedule for data-drift detection, and build\n",
    "a **CloudWatch dashboard** for operational visibility.\n",
    "\n",
    "**Pre-requisite:** Run `1_train_xgboost_binary.ipynb` first — this notebook reads\n",
    "the saved evaluation metrics from S3 to locate the best model artifact.\n",
    "\n",
    "**Sections:**\n",
    "1. Setup & load model artifact\n",
    "2. Deploy endpoint with data capture\n",
    "3. Generate Model Monitor baseline\n",
    "4. Schedule hourly monitoring\n",
    "5. Build CloudWatch dashboard\n",
    "6. Send test traffic\n",
    "7. **Cleanup** — delete all billable resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251d2da",
   "metadata": {},
   "source": [
    "## 1  Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19813d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region : us-east-1\n",
      "Bucket : sagemaker-us-east-1-776673915827\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, io, time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from sagemaker import get_execution_role, image_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import (\n",
    "    DataCaptureConfig,\n",
    "    DefaultModelMonitor,\n",
    "    CronExpressionGenerator,\n",
    ")\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "role   = get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "sm     = boto3.client(\"sagemaker\")\n",
    "s3     = boto3.client(\"s3\")\n",
    "cw     = boto3.client(\"cloudwatch\")\n",
    "\n",
    "s3_prefix = \"aai540/model/xgboost-binary\"\n",
    "\n",
    "print(f\"Region : {region}\")\n",
    "print(f\"Bucket : {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e92836c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training job : xgb-binary-tune-260216-1635-002-30826604\n",
      "Model artifact    : s3://sagemaker-us-east-1-776673915827/aai540/model/xgboost-binary/output/xgb-binary-tune-260216-1635-002-30826604/output/model.tar.gz\n",
      "Test AUC-ROC      : 0.9199\n"
     ]
    }
   ],
   "source": [
    "# ---------- Locate best model artifact from training notebook ----------\n",
    "metrics_key = f\"{s3_prefix}/evaluation/test_metrics.json\"\n",
    "obj = s3.get_object(Bucket=bucket, Key=metrics_key)\n",
    "metrics = json.loads(obj[\"Body\"].read())\n",
    "\n",
    "best_job = metrics[\"best_training_job\"]\n",
    "best_model_s3 = f\"s3://{bucket}/{s3_prefix}/output/{best_job}/output/model.tar.gz\"\n",
    "\n",
    "print(f\"Best training job : {best_job}\")\n",
    "print(f\"Model artifact    : {best_model_s3}\")\n",
    "print(f\"Test AUC-ROC      : {metrics['test_auc_roc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ddd8f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name    : ids-xgboost-binary-monitor\n",
      "Data capture     : s3://sagemaker-us-east-1-776673915827/aai540/model/xgboost-binary/data-capture\n",
      "Baseline prefix  : s3://sagemaker-us-east-1-776673915827/aai540/model/xgboost-binary/monitor/baseline\n",
      "Monitor reports  : s3://sagemaker-us-east-1-776673915827/aai540/model/xgboost-binary/monitor/reports\n"
     ]
    }
   ],
   "source": [
    "# ---------- Constants (must match training notebook) ----------\n",
    "FEATURE_COLS = [\n",
    "    \"duration\", \"pkt_total\", \"bytes_total\",\n",
    "    \"pkt_fwd\", \"pkt_bwd\", \"bytes_fwd\", \"bytes_bwd\",\n",
    "    \"pkt_rate\", \"byte_rate\", \"bytes_per_pkt\",\n",
    "    \"pkt_ratio\", \"byte_ratio\",\n",
    "]\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "ENDPOINT_NAME     = \"ids-xgboost-binary-monitor\"\n",
    "MONITOR_SCHEDULE  = \"ids-xgboost-binary-monitor-schedule\"\n",
    "DASHBOARD_NAME    = \"IDS-XGBoost-Monitoring\"\n",
    "\n",
    "# S3 prefixes for monitoring artefacts\n",
    "data_capture_prefix = f\"s3://{bucket}/{s3_prefix}/data-capture\"\n",
    "baseline_prefix     = f\"s3://{bucket}/{s3_prefix}/monitor/baseline\"\n",
    "monitor_reports     = f\"s3://{bucket}/{s3_prefix}/monitor/reports\"\n",
    "\n",
    "print(f\"Endpoint name    : {ENDPOINT_NAME}\")\n",
    "print(f\"Data capture     : {data_capture_prefix}\")\n",
    "print(f\"Baseline prefix  : {baseline_prefix}\")\n",
    "print(f\"Monitor reports  : {monitor_reports}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5e188",
   "metadata": {},
   "source": [
    "## 2  Deploy Endpoint with Data Capture\n",
    "\n",
    "We create a SageMaker `Model` from the saved artifact and deploy it to a\n",
    "real-time endpoint with `DataCaptureConfig` enabled.  This captures **100 %**\n",
    "of inference requests and responses to S3 so Model Monitor can analyse them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5805090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Endpoint 'ids-xgboost-binary-monitor' already exists (Status: InService)\n",
      "Deleting existing endpoint and config...\n",
      "  ✓ Endpoint deleted\n",
      "  ✓ Endpoint config deleted\n",
      "  Waiting for deletion to complete...\n"
     ]
    }
   ],
   "source": [
    "# Check if endpoint already exists and delete it if necessary\n",
    "try:\n",
    "    existing = sm.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "    print(f\"⚠️  Endpoint '{ENDPOINT_NAME}' already exists (Status: {existing['EndpointStatus']})\")\n",
    "    print(\"Deleting existing endpoint and config...\")\n",
    "    \n",
    "    # Delete endpoint\n",
    "    sm.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "    print(f\"  ✓ Endpoint deleted\")\n",
    "    \n",
    "    # Delete endpoint config\n",
    "    config_name = existing['EndpointConfigName']\n",
    "    sm.delete_endpoint_config(EndpointConfigName=config_name)\n",
    "    print(f\"  ✓ Endpoint config deleted\")\n",
    "    \n",
    "    # Wait for deletion to complete\n",
    "    import time\n",
    "    print(\"  Waiting for deletion to complete...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "except sm.exceptions.ClientError as e:\n",
    "    if 'Could not find endpoint' in str(e):\n",
    "        print(f\"✓ No existing endpoint '{ENDPOINT_NAME}' — ready to deploy\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61e4355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!\n",
      "✓ Endpoint deployed: ids-xgboost-binary-monitor\n"
     ]
    }
   ],
   "source": [
    "xgb_image = image_uris.retrieve(\"xgboost\", region, version=\"1.5-1\")\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=data_capture_prefix,\n",
    "    capture_options=[\"Input\", \"Output\"],\n",
    "    csv_content_types=[\"text/csv\"],\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=xgb_image,\n",
    "    model_data=best_model_s3,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    data_capture_config=data_capture_config,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    "    wait=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Endpoint deployed: {ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb1b9d3",
   "metadata": {},
   "source": [
    "## 3  Generate Model Monitor Baseline\n",
    "\n",
    "The baseline job analyses the **training data** to compute per-feature\n",
    "statistics (mean, std-dev, min, max, distribution) and constraints\n",
    "(data types, completeness).  Model Monitor will compare live inference\n",
    "data against these baselines to detect drift.\n",
    "\n",
    "> **Note:** `suggest_baseline()` launches a SageMaker Processing job that\n",
    "> typically takes **5 – 10 minutes** to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5af9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: s3://sagemaker-us-east-1-776673915827/aai540/model/xgboost-binary/train/data.csv\n",
      "Size: 12.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Path to training CSV already in S3 (uploaded by training notebook)\n",
    "s3_train_uri = f\"s3://{bucket}/{s3_prefix}/train/data.csv\"\n",
    "print(f\"Training data: {s3_train_uri}\")\n",
    "\n",
    "# Verify it exists\n",
    "head = s3.head_object(Bucket=bucket, Key=f\"{s3_prefix}/train/data.csv\")\n",
    "print(f\"Size: {head['ContentLength'] / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27bbaaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name baseline-suggestion-job-2026-02-16-17-24-31-924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching baseline job (this takes ~5-10 min) …\n",
      "...........................................................!✓ Baseline job complete.\n"
     ]
    }
   ],
   "source": [
    "monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size_in_gb=10,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "print(\"Launching baseline job...\")\n",
    "monitor.suggest_baseline(\n",
    "    baseline_dataset=s3_train_uri,\n",
    "    dataset_format=DatasetFormat.csv(header=False),\n",
    "    output_s3_uri=baseline_prefix,\n",
    "    wait=True,\n",
    "    logs=False,\n",
    ")\n",
    "print(\"Baseline job complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4e98e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  Baseline Statistics (first 5 features)\n",
      "============================================================\n",
      "                   _c0  mean=0.7736095604764217  stddev=0.4184946934142613\n",
      "                   _c1  mean=0.000399019465402325  stddev=0.0015258257248348041\n",
      "                   _c2  mean=3.0537201047366813  stddev=4.609643980111558\n",
      "                   _c3  mean=220328.14460370783  stddev=20075147.993305646\n",
      "                   _c4  mean=1.6787407566874772  stddev=2.394221759371462\n",
      "\n",
      "  Total features tracked: 13\n",
      "\n",
      "============================================================\n",
      "  Baseline Constraints (first 5 features)\n",
      "============================================================\n",
      "                   _c0  type=Integral  completeness=1.0\n",
      "                   _c1  type=Fractional  completeness=1.0\n",
      "                   _c2  type=Integral  completeness=1.0\n",
      "                   _c3  type=Integral  completeness=1.0\n",
      "                   _c4  type=Integral  completeness=1.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect baseline outputs\n",
    "baseline_job = monitor.latest_baselining_job\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Baseline Statistics (first 5 features)\")\n",
    "print(\"=\" * 60)\n",
    "schema = baseline_job.baseline_statistics().body_dict[\"features\"]\n",
    "for feat in schema[:5]:\n",
    "    name = feat[\"name\"]\n",
    "    num  = feat.get(\"numerical_statistics\", {})\n",
    "    print(f\"  {name:>20s}  mean={num.get('mean', 'N/A'):>12}  \"\n",
    "          f\"stddev={num.get('std_dev', 'N/A'):>12}\")\n",
    "\n",
    "print(f\"\\n  Total features tracked: {len(schema)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  Baseline Constraints (first 5 features)\")\n",
    "print(\"=\" * 60)\n",
    "constraints = baseline_job.suggested_constraints().body_dict[\"features\"]\n",
    "for feat in constraints[:5]:\n",
    "    print(f\"  {feat['name']:>20s}  type={feat['inferred_type']}  \"\n",
    "          f\"completeness={feat.get('completeness', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ac077",
   "metadata": {},
   "source": [
    "## 4  Schedule Hourly Monitoring\n",
    "\n",
    "The monitoring schedule runs every hour.  Each execution compares the data\n",
    "captured by the endpoint against the baseline statistics and constraints,\n",
    "then writes a violation report to S3 and emits CloudWatch metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d33cebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: ids-xgboost-binary-monitor-schedule\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Monitoring schedule created: ids-xgboost-binary-monitor-schedule\n",
      "  Cron    : cron(0 * ? * * *)\n",
      "  Reports : s3://sagemaker-us-east-1-776673915827/aai540/model/xgboost-binary/monitor/reports\n"
     ]
    }
   ],
   "source": [
    "monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=MONITOR_SCHEDULE,\n",
    "    endpoint_input=ENDPOINT_NAME,\n",
    "    output_s3_uri=monitor_reports,\n",
    "    statistics=monitor.baseline_statistics(),\n",
    "    constraints=monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    ")\n",
    "\n",
    "print(f\"✓ Monitoring schedule created: {MONITOR_SCHEDULE}\")\n",
    "print(f\"  Cron    : {CronExpressionGenerator.hourly()}\")\n",
    "print(f\"  Reports : {monitor_reports}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6f617df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule status: Pending\n"
     ]
    }
   ],
   "source": [
    "# Verify schedule status\n",
    "desc = sm.describe_monitoring_schedule(MonitoringScheduleName=MONITOR_SCHEDULE)\n",
    "print(f\"Schedule status: {desc['MonitoringScheduleStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d137d2",
   "metadata": {},
   "source": [
    "## 5  CloudWatch Dashboard\n",
    "\n",
    "A CloudWatch dashboard provides a single-pane view of endpoint health\n",
    "and model quality.  The dashboard includes:\n",
    "- **Invocation metrics** — request count, latency (avg / p99)\n",
    "- **Error rates** — 4xx and 5xx responses\n",
    "- **Model Monitor** — a text widget linking to the monitor schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d0dc284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CloudWatch dashboard created: IDS-XGBoost-Monitoring\n",
      "  Console URL: https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards/dashboard/IDS-XGBoost-Monitoring\n"
     ]
    }
   ],
   "source": [
    "dashboard_body = {\n",
    "    \"widgets\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"x\": 0, \"y\": 0, \"width\": 24, \"height\": 2,\n",
    "            \"properties\": {\n",
    "                \"markdown\": (\n",
    "                    f\"# IDS XGBoost Binary — Endpoint Monitoring\\n\"\n",
    "                    f\"**Endpoint:** `{ENDPOINT_NAME}` &nbsp; | &nbsp; \"\n",
    "                    f\"**Monitor schedule:** `{MONITOR_SCHEDULE}` &nbsp; | &nbsp; \"\n",
    "                    f\"**Region:** `{region}`\"\n",
    "                )\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"x\": 0, \"y\": 2, \"width\": 8, \"height\": 6,\n",
    "            \"properties\": {\n",
    "                \"title\": \"Invocations\",\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"Invocations\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"Sum\", \"period\": 60}]\n",
    "                ],\n",
    "                \"view\": \"timeSeries\",\n",
    "                \"region\": region,\n",
    "                \"period\": 60,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"x\": 8, \"y\": 2, \"width\": 8, \"height\": 6,\n",
    "            \"properties\": {\n",
    "                \"title\": \"Model Latency (ms)\",\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"ModelLatency\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"Average\", \"period\": 60,\n",
    "                      \"label\": \"Avg\"}],\n",
    "                    [\"AWS/SageMaker\", \"ModelLatency\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"p99\", \"period\": 60,\n",
    "                      \"label\": \"p99\"}],\n",
    "                ],\n",
    "                \"view\": \"timeSeries\",\n",
    "                \"region\": region,\n",
    "                \"period\": 60,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"x\": 16, \"y\": 2, \"width\": 8, \"height\": 6,\n",
    "            \"properties\": {\n",
    "                \"title\": \"Overhead Latency (ms)\",\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"OverheadLatency\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"Average\", \"period\": 60,\n",
    "                      \"label\": \"Avg\"}],\n",
    "                    [\"AWS/SageMaker\", \"OverheadLatency\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"p99\", \"period\": 60,\n",
    "                      \"label\": \"p99\"}],\n",
    "                ],\n",
    "                \"view\": \"timeSeries\",\n",
    "                \"region\": region,\n",
    "                \"period\": 60,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"x\": 0, \"y\": 8, \"width\": 8, \"height\": 6,\n",
    "            \"properties\": {\n",
    "                \"title\": \"4xx Errors\",\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"Invocation4XXErrors\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"Sum\", \"period\": 60}]\n",
    "                ],\n",
    "                \"view\": \"timeSeries\",\n",
    "                \"region\": region,\n",
    "                \"period\": 60,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"x\": 8, \"y\": 8, \"width\": 8, \"height\": 6,\n",
    "            \"properties\": {\n",
    "                \"title\": \"5xx Errors\",\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"Invocation5XXErrors\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"Sum\", \"period\": 60}]\n",
    "                ],\n",
    "                \"view\": \"timeSeries\",\n",
    "                \"region\": region,\n",
    "                \"period\": 60,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"metric\",\n",
    "            \"x\": 16, \"y\": 8, \"width\": 8, \"height\": 6,\n",
    "            \"properties\": {\n",
    "                \"title\": \"Invocations Per Instance\",\n",
    "                \"metrics\": [\n",
    "                    [\"AWS/SageMaker\", \"InvocationsPerInstance\",\n",
    "                     \"EndpointName\", ENDPOINT_NAME,\n",
    "                     \"VariantName\", \"AllTraffic\",\n",
    "                     {\"stat\": \"Sum\", \"period\": 60}]\n",
    "                ],\n",
    "                \"view\": \"timeSeries\",\n",
    "                \"region\": region,\n",
    "                \"period\": 60,\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "cw.put_dashboard(\n",
    "    DashboardName=DASHBOARD_NAME,\n",
    "    DashboardBody=json.dumps(dashboard_body),\n",
    ")\n",
    "\n",
    "console_url = (\n",
    "    f\"https://{region}.console.aws.amazon.com/cloudwatch/home\"\n",
    "    f\"?region={region}#dashboards/dashboard/{DASHBOARD_NAME}\"\n",
    ")\n",
    "print(f\"✓ CloudWatch dashboard created: {DASHBOARD_NAME}\")\n",
    "print(f\"  Console URL: {console_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab56a47d",
   "metadata": {},
   "source": [
    "## 6  Send Test Traffic\n",
    "\n",
    "Send a batch of test-set samples through the endpoint so that\n",
    "data capture files are written and CloudWatch metrics begin to populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a289eebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictor from existing endpoint...\n",
      "✓ Predictor attached to endpoint: ids-xgboost-binary-monitor\n"
     ]
    }
   ],
   "source": [
    "# Attach to the deployed endpoint (in case predictor is None)\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "if predictor is None:\n",
    "    print(\"Creating predictor from existing endpoint...\")\n",
    "    predictor = Predictor(\n",
    "        endpoint_name=ENDPOINT_NAME,\n",
    "        sagemaker_session=sess,\n",
    "        serializer=sagemaker.serializers.CSVSerializer(),\n",
    "        deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    "    )\n",
    "    print(f\"✓ Predictor attached to endpoint: {ENDPOINT_NAME}\")\n",
    "else:\n",
    "    print(f\"✓ Predictor already exists for endpoint: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "788861d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rows loaded: 49,920\n"
     ]
    }
   ],
   "source": [
    "# Load test data from Athena (same query as training notebook)\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "database_name = \"aai540_eda\"\n",
    "engine = create_engine(\n",
    "    f\"awsathena+rest://@athena.{region}.amazonaws.com:443/{database_name}\",\n",
    "    connect_args={\n",
    "        \"s3_staging_dir\": f\"s3://{bucket}/athena/staging/\",\n",
    "        \"region_name\": region,\n",
    "    },\n",
    ")\n",
    "\n",
    "columns = \", \".join([LABEL_COL] + FEATURE_COLS)\n",
    "query = f\"\"\"\n",
    "SELECT {columns}\n",
    "FROM {database_name}.dataset_split\n",
    "WHERE data_split = 'test'\n",
    "\"\"\"\n",
    "df_test = pd.read_sql(query, engine)\n",
    "print(f\"Test rows loaded: {len(df_test):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98c63592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending 49,920 samples to endpoint in batches of 500 …\n",
      "\n",
      "✓ Predictions complete.\n",
      "  Accuracy : 0.2414\n",
      "  AUC-ROC  : 0.9199\n",
      "\n",
      "Data capture files will appear in S3 within ~2 minutes.\n",
      "CloudWatch metrics will populate within ~5 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Send predictions in batches\n",
    "BATCH_SIZE = 500\n",
    "X_test = df_test[FEATURE_COLS].values\n",
    "y_true = df_test[LABEL_COL].values\n",
    "y_prob = []\n",
    "\n",
    "print(f\"Sending {len(X_test):,} samples to endpoint in batches of {BATCH_SIZE} …\")\n",
    "for start in range(0, len(X_test), BATCH_SIZE):\n",
    "    batch = X_test[start : start + BATCH_SIZE]\n",
    "    response = predictor.predict(batch)\n",
    "    y_prob.extend([float(row[0]) for row in response])\n",
    "\n",
    "y_prob = np.array(y_prob)\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "print(f\"\\n✓ Predictions complete.\")\n",
    "print(f\"  Accuracy : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"  AUC-ROC  : {roc_auc_score(y_true, y_prob):.4f}\")\n",
    "print(f\"\\nData capture files will appear in S3 within ~2 minutes.\")\n",
    "print(f\"CloudWatch metrics will populate within ~5 minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a956185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 120 seconds for data capture delivery …\n",
      "✓ Data capture active — 1 file(s) found:\n",
      "  s3://sagemaker-us-east-1-776673915827/aai540/model/xgboost-binary/data-capture/ids-xgboost-binary-monitor/AllTraffic/2026/02/16/17/31-50-626-e4a1d55d-a872-4a02-b184-a6e26fc103db.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Verify data capture files exist\n",
    "import time\n",
    "print(\"Waiting 120 seconds for data capture delivery …\")\n",
    "time.sleep(120)\n",
    "\n",
    "capture_prefix_key = f\"{s3_prefix}/data-capture/{ENDPOINT_NAME}\"\n",
    "result = s3.list_objects_v2(Bucket=bucket, Prefix=capture_prefix_key, MaxKeys=5)\n",
    "\n",
    "if \"Contents\" in result:\n",
    "    print(f\"✓ Data capture active — {len(result['Contents'])} file(s) found:\")\n",
    "    for obj in result[\"Contents\"][:5]:\n",
    "        print(f\"  s3://{bucket}/{obj['Key']}\")\n",
    "else:\n",
    "    print(\"⏳ No capture files yet — they may take a few more minutes to appear.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd333d27",
   "metadata": {},
   "source": [
    "## 7  Cleanup\n",
    "\n",
    "⚠️ **Run this cell to delete all billable resources** created by this notebook:\n",
    "- Model Monitor schedule\n",
    "- SageMaker endpoint and endpoint configuration\n",
    "- SageMaker model\n",
    "- CloudWatch dashboard\n",
    "\n",
    "The model artifact in S3 is **not** deleted (it is needed for redeployment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f87fe582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\" * 60)\n",
    "# print(\"  CLEANUP — Deleting billable resources\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# # 1. Delete monitoring schedule\n",
    "# try:\n",
    "#     monitor.delete_monitoring_schedule()\n",
    "#     print(\"✓ Monitoring schedule deleted.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"⚠ Monitoring schedule: {e}\")\n",
    "\n",
    "# # 2. Delete endpoint (also stops the running instance)\n",
    "# try:\n",
    "#     predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "#     print(\"✓ Endpoint and endpoint config deleted.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"⚠ Endpoint: {e}\")\n",
    "\n",
    "# # 3. Delete model\n",
    "# try:\n",
    "#     sm.delete_model(ModelName=ENDPOINT_NAME)\n",
    "#     print(\"✓ SageMaker model deleted.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"⚠ Model: {e}\")\n",
    "\n",
    "# # 4. Delete CloudWatch dashboard\n",
    "# try:\n",
    "#     cw.delete_dashboards(DashboardNames=[DASHBOARD_NAME])\n",
    "#     print(\"✓ CloudWatch dashboard deleted.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"⚠ Dashboard: {e}\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"  Cleanup complete.\")\n",
    "# print(f\"  Model artifact preserved at: {best_model_s3}\")\n",
    "# print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
