{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9183c3af",
   "metadata": {},
   "source": [
    "# Traffic Simulation for Monitoring Dashboard\n",
    "\n",
    "Send periodic inference requests to the deployed endpoint to simulate\n",
    "real-world traffic patterns and populate CloudWatch metrics and Model Monitor data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cafafac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a79575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Region   : us-east-1\n",
      "Endpoint : ids-xgboost-binary-monitor\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from sagemaker.predictor import Predictor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "s3_prefix = \"aai540/model/xgboost-binary\"\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"duration\", \"pkt_total\", \"bytes_total\",\n",
    "    \"pkt_fwd\", \"pkt_bwd\", \"bytes_fwd\", \"bytes_bwd\",\n",
    "    \"pkt_rate\", \"byte_rate\", \"bytes_per_pkt\",\n",
    "    \"pkt_ratio\", \"byte_ratio\",\n",
    "]\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "ENDPOINT_NAME = \"ids-xgboost-binary-monitor\"\n",
    "\n",
    "print(f\"Region   : {region}\")\n",
    "print(f\"Endpoint : {ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa313b",
   "metadata": {},
   "source": [
    "## Load Production Data\n",
    "\n",
    "Using the production holdout dataset (40% split) which represents truly unseen data\n",
    "that wasn't used for training, validation, or testing. This simulates real production\n",
    "inference traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46fe2499-5c52-41f3-8f51-c9843af4393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading production data from S3...\n",
      "Production rows loaded: 200,308\n"
     ]
    }
   ],
   "source": [
    "# S3 path where production holdout was exported\n",
    "prod_s3_path = f\"s3://{bucket}/aai540/production_holdout/production_data.csv\"\n",
    "\n",
    "print(\"Loading production data from S3...\")\n",
    "df_prod = pd.read_csv(prod_s3_path)\n",
    "\n",
    "print(f\"Production rows loaded: {len(df_prod):,}\")\n",
    "\n",
    "# keep the rest of your notebook unchanged\n",
    "X_test = df_prod[FEATURE_COLS].values\n",
    "y_true = df_prod[LABEL_COL].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa9ddc",
   "metadata": {},
   "source": [
    "## Connect to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919edb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to endpoint: ids-xgboost-binary-monitor\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")\n",
    "print(f\"Connected to endpoint: {ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01039b58",
   "metadata": {},
   "source": [
    "## Traffic Simulation Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc76cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic Simulation Configuration\n",
      "  Duration        : 60 minutes (1.0 hours)\n",
      "  Interval        : 60 seconds between batches\n",
      "  Batch size      : 50-200 samples (avg ~100)\n",
      "  Total batches   : 60\n",
      "  Est. requests   : ~6,000 (variable load)\n",
      "\n",
      "Start time: 2026-02-20 20:06:51\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DURATION_MINUTES = 60       # Total simulation duration (1 hour)\n",
    "INTERVAL_SECONDS = 60        # Time between batches\n",
    "BATCH_SIZE_MIN = 50          # Minimum samples per batch\n",
    "BATCH_SIZE_MAX = 200         # Maximum samples per batch\n",
    "BATCH_SIZE_AVG = 100         # Average samples per batch\n",
    "\n",
    "total_iterations = (DURATION_MINUTES * 60) // INTERVAL_SECONDS\n",
    "\n",
    "print(\"Traffic Simulation Configuration\")\n",
    "\n",
    "print(f\"  Duration        : {DURATION_MINUTES} minutes ({DURATION_MINUTES/60:.1f} hours)\")\n",
    "print(f\"  Interval        : {INTERVAL_SECONDS} seconds between batches\")\n",
    "print(f\"  Batch size      : {BATCH_SIZE_MIN}-{BATCH_SIZE_MAX} samples (avg ~{BATCH_SIZE_AVG})\")\n",
    "print(f\"  Total batches   : {total_iterations}\")\n",
    "print(f\"  Est. requests   : ~{total_iterations * BATCH_SIZE_AVG:,} (variable load)\")\n",
    "print(f\"\\nStart time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead67edd",
   "metadata": {},
   "source": [
    "## Run Simulation\n",
    "\n",
    "This cell will run for the configured duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e950d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:06:58] Batch 1/60 | Samples:  70 | Latency: 73ms | Batch Acc: 0.343 | Cumulative Acc: 0.3429 | Remaining: 59m 0s\n",
      "[20:07:58] Batch 2/60 | Samples:  64 | Latency: 14ms | Batch Acc: 0.156 | Cumulative Acc: 0.2537 | Remaining: 58m 0s\n",
      "[20:08:59] Batch 3/60 | Samples:  74 | Latency: 15ms | Batch Acc: 0.270 | Cumulative Acc: 0.2596 | Remaining: 57m 0s\n",
      "[20:09:59] Batch 4/60 | Samples:  79 | Latency: 15ms | Batch Acc: 0.203 | Cumulative Acc: 0.2439 | Remaining: 56m 0s\n",
      "[20:10:59] Batch 5/60 | Samples:  79 | Latency: 15ms | Batch Acc: 0.215 | Cumulative Acc: 0.2377 | Remaining: 55m 0s\n",
      "[20:11:59] Batch 6/60 | Samples:  79 | Latency: 75ms | Batch Acc: 0.266 | Cumulative Acc: 0.2427 | Remaining: 54m 0s\n",
      "[20:12:59] Batch 7/60 | Samples:  99 | Latency: 15ms | Batch Acc: 0.202 | Cumulative Acc: 0.2353 | Remaining: 53m 0s\n",
      "[20:13:59] Batch 8/60 | Samples:  88 | Latency: 15ms | Batch Acc: 0.250 | Cumulative Acc: 0.2373 | Remaining: 52m 0s\n",
      "[20:14:59] Batch 9/60 | Samples:  84 | Latency: 15ms | Batch Acc: 0.274 | Cumulative Acc: 0.2416 | Remaining: 51m 0s\n",
      "[20:15:59] Batch 10/60 | Samples:  88 | Latency: 14ms | Batch Acc: 0.182 | Cumulative Acc: 0.2351 | Remaining: 50m 0s\n",
      "[20:16:59] Batch 11/60 | Samples: 106 | Latency: 70ms | Batch Acc: 0.311 | Cumulative Acc: 0.2440 | Remaining: 49m 0s\n",
      "[20:17:59] Batch 12/60 | Samples: 102 | Latency: 15ms | Batch Acc: 0.216 | Cumulative Acc: 0.2411 | Remaining: 48m 0s\n",
      "[20:18:59] Batch 13/60 | Samples: 105 | Latency: 15ms | Batch Acc: 0.200 | Cumulative Acc: 0.2372 | Remaining: 47m 0s\n",
      "[20:19:59] Batch 14/60 | Samples: 112 | Latency: 15ms | Batch Acc: 0.179 | Cumulative Acc: 0.2319 | Remaining: 46m 0s\n",
      "[20:20:59] Batch 15/60 | Samples:  93 | Latency: 15ms | Batch Acc: 0.204 | Cumulative Acc: 0.2300 | Remaining: 45m 0s\n",
      "[20:21:59] Batch 16/60 | Samples:  89 | Latency: 73ms | Batch Acc: 0.202 | Cumulative Acc: 0.2282 | Remaining: 44m 0s\n",
      "[20:22:59] Batch 17/60 | Samples:  97 | Latency: 15ms | Batch Acc: 0.196 | Cumulative Acc: 0.2261 | Remaining: 43m 0s\n",
      "\n",
      "Simulation interrupted at batch 17/60\n",
      "Simulation Complete\n",
      "  Batches sent    : 17/60\n",
      "  Total samples   : 1,508\n",
      "  Overall accuracy: 0.2261\n",
      "  End time        : 2026-02-20 20:23:13\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "all_actuals = []\n",
    "iteration = 0\n",
    "\n",
    "try:\n",
    "    for i in range(total_iterations):\n",
    "        iteration = i + 1\n",
    "        \n",
    "        # Variable batch size to simulate realistic traffic patterns\n",
    "        # Create periods of high/medium/low traffic\n",
    "        hour_position = (i / total_iterations) * DURATION_MINUTES / 60\n",
    "        \n",
    "        # Sine wave pattern for natural variation + random noise\n",
    "        traffic_cycle = np.sin(hour_position * 2 * np.pi) * 0.3 + 0.7  # 0.4 to 1.0\n",
    "        random_variation = np.random.uniform(0.85, 1.15)  # Â±15% random noise\n",
    "        \n",
    "        batch_size = int(BATCH_SIZE_AVG * traffic_cycle * random_variation)\n",
    "        batch_size = max(BATCH_SIZE_MIN, min(BATCH_SIZE_MAX, batch_size))  # Clamp\n",
    "        \n",
    "        # Random sample from test set\n",
    "        indices = np.random.choice(len(X_test), size=batch_size, replace=False)\n",
    "        batch_X = X_test[indices]\n",
    "        batch_y = y_true[indices]\n",
    "        \n",
    "        # Send predictions\n",
    "        start_time = time.time()\n",
    "        response = predictor.predict(batch_X)\n",
    "        latency = (time.time() - start_time) * 1000  # ms\n",
    "        \n",
    "        # Parse predictions\n",
    "        y_prob = np.array([float(row[0]) for row in response])\n",
    "        y_pred = (y_prob >= 0.5).astype(int)\n",
    "        \n",
    "        # Track results\n",
    "        all_predictions.extend(y_pred)\n",
    "        all_actuals.extend(batch_y)\n",
    "        \n",
    "        # Compute running metrics\n",
    "        batch_accuracy = accuracy_score(batch_y, y_pred)\n",
    "        cumulative_accuracy = accuracy_score(all_actuals, all_predictions)\n",
    "        \n",
    "        # Progress update\n",
    "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "        elapsed = i * INTERVAL_SECONDS\n",
    "        remaining = (total_iterations - i - 1) * INTERVAL_SECONDS\n",
    "        \n",
    "        print(\n",
    "            f\"[{timestamp}] Batch {iteration}/{total_iterations} | \"\n",
    "            f\"Samples: {batch_size:3d} | Latency: {latency:.0f}ms | \"\n",
    "            f\"Batch Acc: {batch_accuracy:.3f} | \"\n",
    "            f\"Cumulative Acc: {cumulative_accuracy:.4f} | \"\n",
    "            f\"Remaining: {remaining//60}m {remaining%60}s\"\n",
    "        )\n",
    "        \n",
    "        # Wait before next batch (unless last iteration)\n",
    "        if i < total_iterations - 1:\n",
    "            time.sleep(INTERVAL_SECONDS)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\nSimulation interrupted at batch {iteration}/{total_iterations}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"Simulation Complete\")\n",
    "print(f\"  Batches sent    : {iteration}/{total_iterations}\")\n",
    "print(f\"  Total samples   : {len(all_predictions):,}\")\n",
    "print(f\"  Overall accuracy: {accuracy_score(all_actuals, all_predictions):.4f}\")\n",
    "print(f\"  End time        : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba0adf",
   "metadata": {},
   "source": [
    "## Quick Dashboard Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e39d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CloudWatch Dashboard:\n",
      "https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards/dashboard/IDS-XGBoost-Monitoring\n"
     ]
    }
   ],
   "source": [
    "dashboard_url = (\n",
    "    f\"https://{region}.console.aws.amazon.com/cloudwatch/home\"\n",
    "    f\"?region={region}#dashboards/dashboard/IDS-XGBoost-Monitoring\"\n",
    ")\n",
    "print(\"CloudWatch Dashboard:\")\n",
    "print(dashboard_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
