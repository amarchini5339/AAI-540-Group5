{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9183c3af",
   "metadata": {},
   "source": [
    "# Traffic Simulation for Monitoring Dashboard\n",
    "\n",
    "**Goal:** Send periodic inference requests to the deployed endpoint to simulate\n",
    "real-world traffic patterns and populate CloudWatch metrics and Model Monitor data.\n",
    "\n",
    "**Pre-requisite:** Run `2_deploy_and_monitor.ipynb` first to deploy the endpoint.\n",
    "\n",
    "**Traffic Pattern:**\n",
    "- Sends batches of predictions every 60 seconds\n",
    "- Configurable duration (default: 30 minutes)\n",
    "- Uses test dataset samples in random order\n",
    "- Displays real-time progress and accuracy\n",
    "\n",
    "**Use Case:**\n",
    "- Populate CloudWatch dashboard with live metrics\n",
    "- Generate data capture files for Model Monitor\n",
    "- Demonstrate monitoring capabilities over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cafafac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a79575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region   : us-east-1\n",
      "Endpoint : ids-xgboost-binary-monitor\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from sagemaker.predictor import Predictor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "s3_prefix = \"aai540/model/xgboost-binary\"\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"duration\", \"pkt_total\", \"bytes_total\",\n",
    "    \"pkt_fwd\", \"pkt_bwd\", \"bytes_fwd\", \"bytes_bwd\",\n",
    "    \"pkt_rate\", \"byte_rate\", \"bytes_per_pkt\",\n",
    "    \"pkt_ratio\", \"byte_ratio\",\n",
    "]\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "ENDPOINT_NAME = \"ids-xgboost-binary-monitor\"\n",
    "\n",
    "print(f\"Region   : {region}\")\n",
    "print(f\"Endpoint : {ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa313b",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f340011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from Athena...\n",
      "âœ“ Test rows loaded: 49,920\n"
     ]
    }
   ],
   "source": [
    "# Load test data from Athena\n",
    "database_name = \"aai540_eda\"\n",
    "engine = create_engine(\n",
    "    f\"awsathena+rest://@athena.{region}.amazonaws.com:443/{database_name}\",\n",
    "    connect_args={\n",
    "        \"s3_staging_dir\": f\"s3://{bucket}/athena/staging/\",\n",
    "        \"region_name\": region,\n",
    "    },\n",
    ")\n",
    "\n",
    "columns = \", \".join([LABEL_COL] + FEATURE_COLS)\n",
    "query = f\"\"\"\n",
    "SELECT {columns}\n",
    "FROM {database_name}.dataset_split\n",
    "WHERE data_split = 'test'\n",
    "\"\"\"\n",
    "print(\"Loading test data from Athena...\")\n",
    "df_test = pd.read_sql(query, engine)\n",
    "print(f\"âœ“ Test rows loaded: {len(df_test):,}\")\n",
    "\n",
    "X_test = df_test[FEATURE_COLS].values\n",
    "y_true = df_test[LABEL_COL].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa9ddc",
   "metadata": {},
   "source": [
    "## Connect to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "919edb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Connected to endpoint: ids-xgboost-binary-monitor\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")\n",
    "print(f\"âœ“ Connected to endpoint: {ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01039b58",
   "metadata": {},
   "source": [
    "## Traffic Simulation Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cc76cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  Traffic Simulation Configuration\n",
      "============================================================\n",
      "  Duration        : 180 minutes (3.0 hours)\n",
      "  Interval        : 60 seconds between batches\n",
      "  Batch size      : 100 samples\n",
      "  Total batches   : 180\n",
      "  Total requests  : 18,000\n",
      "============================================================\n",
      "\n",
      "Start time: 2026-02-17 00:50:44\n",
      "Expected end: 2026-02-17 00:50:44 + 180 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DURATION_MINUTES = 180       # Total simulation duration (3 hours)\n",
    "INTERVAL_SECONDS = 60        # Time between batches\n",
    "BATCH_SIZE = 100             # Samples per batch\n",
    "\n",
    "total_iterations = (DURATION_MINUTES * 60) // INTERVAL_SECONDS\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Traffic Simulation Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Duration        : {DURATION_MINUTES} minutes ({DURATION_MINUTES/60:.1f} hours)\")\n",
    "print(f\"  Interval        : {INTERVAL_SECONDS} seconds between batches\")\n",
    "print(f\"  Batch size      : {BATCH_SIZE} samples\")\n",
    "print(f\"  Total batches   : {total_iterations}\")\n",
    "print(f\"  Total requests  : {total_iterations * BATCH_SIZE:,}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nStart time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Expected end: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} + {DURATION_MINUTES} min\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead67edd",
   "metadata": {},
   "source": [
    "## Run Simulation\n",
    "\n",
    "This cell will run for the configured duration. You can interrupt it at any time with the stop button.\n",
    "\n",
    "**Monitoring Tips:**\n",
    "- Open the CloudWatch dashboard in another browser tab\n",
    "- Metrics update every 1-5 minutes\n",
    "- Data capture files appear in S3 within ~2 minutes\n",
    "- Model Monitor runs on the next hourly schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e950d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:50:45] Batch 1/180 | Samples: 100 | Latency: 83ms | Batch Acc: 0.230 | Cumulative Acc: 0.2300 | Remaining: 179m 0s\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "all_actuals = []\n",
    "iteration = 0\n",
    "\n",
    "try:\n",
    "    for i in range(total_iterations):\n",
    "        iteration = i + 1\n",
    "        \n",
    "        # Random sample from test set\n",
    "        indices = np.random.choice(len(X_test), size=BATCH_SIZE, replace=False)\n",
    "        batch_X = X_test[indices]\n",
    "        batch_y = y_true[indices]\n",
    "        \n",
    "        # Send predictions\n",
    "        start_time = time.time()\n",
    "        response = predictor.predict(batch_X)\n",
    "        latency = (time.time() - start_time) * 1000  # ms\n",
    "        \n",
    "        # Parse predictions\n",
    "        y_prob = np.array([float(row[0]) for row in response])\n",
    "        y_pred = (y_prob >= 0.5).astype(int)\n",
    "        \n",
    "        # Track results\n",
    "        all_predictions.extend(y_pred)\n",
    "        all_actuals.extend(batch_y)\n",
    "        \n",
    "        # Compute running metrics\n",
    "        batch_accuracy = accuracy_score(batch_y, y_pred)\n",
    "        cumulative_accuracy = accuracy_score(all_actuals, all_predictions)\n",
    "        \n",
    "        # Progress update\n",
    "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "        elapsed = i * INTERVAL_SECONDS\n",
    "        remaining = (total_iterations - i - 1) * INTERVAL_SECONDS\n",
    "        \n",
    "        print(\n",
    "            f\"[{timestamp}] Batch {iteration}/{total_iterations} | \"\n",
    "            f\"Samples: {BATCH_SIZE} | Latency: {latency:.0f}ms | \"\n",
    "            f\"Batch Acc: {batch_accuracy:.3f} | \"\n",
    "            f\"Cumulative Acc: {cumulative_accuracy:.4f} | \"\n",
    "            f\"Remaining: {remaining//60}m {remaining%60}s\"\n",
    "        )\n",
    "        \n",
    "        # Wait before next batch (unless last iteration)\n",
    "        if i < total_iterations - 1:\n",
    "            time.sleep(INTERVAL_SECONDS)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\nâš ï¸  Simulation interrupted at batch {iteration}/{total_iterations}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  Simulation Complete\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Batches sent    : {iteration}/{total_iterations}\")\n",
    "print(f\"  Total samples   : {len(all_predictions):,}\")\n",
    "print(f\"  Overall accuracy: {accuracy_score(all_actuals, all_predictions):.4f}\")\n",
    "print(f\"  End time        : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸ’¡ Check your CloudWatch dashboard for updated metrics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba0adf",
   "metadata": {},
   "source": [
    "## Quick Dashboard Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_url = (\n",
    "    f\"https://{region}.console.aws.amazon.com/cloudwatch/home\"\n",
    "    f\"?region={region}#dashboards/dashboard/IDS-XGBoost-Monitoring\"\n",
    ")\n",
    "print(\"CloudWatch Dashboard:\")\n",
    "print(dashboard_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
